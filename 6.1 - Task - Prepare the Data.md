---
type: task
previous-task: "[[6.0 - Model Building]]"
data-inputs:
  - all_extracted_data.csv
data-outputs: 
skills:
---
# 6.1 - Task - Prepare the Data

Let's try to predict some revenues!



```python
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, root_mean_squared_error

```


```python
pgh_revenue_data = pd.read_csv("inputs/all_extracted_data.csv")
pgh_revenue_data.head()
```


```python
# Combine `year` and `quarter` into a single column for the X-axis
pgh_revenue_data['Year-Quarter'] = pgh_revenue_data['year'].astype(str) + '-' + pgh_revenue_data['quarter']
```


```python
# create a copy of just the data we want
revenues = pgh_revenue_data[['Year-Quarter', 'revenue by claude api']].copy()
revenues = revenues.rename(columns={"revenue by claude api":"revenue"})
revenues
```

## Is the data stationary?



```python
import matplotlib.pyplot as plt
# Plot the time series
plt.figure(figsize=(14, 8))

plt.plot(revenues['Year-Quarter'], revenues['revenue'])
plt.xticks(rotation=45, fontsize=10)

plt.title("Time Series Plot")
plt.show()
```

hrm.

let's calculate rolling mean


```python
plt.figure(figsize=(14, 8))


window_size = 4  # Rolling window size (e.g., 4 quarters)
rolling_mean = revenues['revenue'].rolling(window=window_size).mean()
rolling_std = revenues['revenue'].rolling(window=window_size).std()

plt.plot(revenues['Year-Quarter'], revenues['revenue'], label="Original Data")
plt.plot(rolling_mean, label="Rolling Mean", color="orange")
plt.plot(rolling_std, label="Rolling Std Dev", color="green")
plt.xticks(rotation=45, fontsize=10)

plt.legend()
plt.show()
```

hrm.

I don't feel like installing python statsmodels to try and use fancy math like ADF to test for stationary. A visual inspection seems to indicate a seasonality.

Perhaps we should do seasonal lags?

## Feature Engineering

Let's make features for our statistical models. We want features to be the inputs to our modeling function.


```python
# create lagged features
# lagging by 2 and 3 because we are two months behind
revenues['lag_1'] = revenues['revenue'].shift(2)
revenues['lag_2'] = revenues['revenue'].shift(3)
revenues['year_lag'] = revenues['revenue'].shift(4)

# get rid of missing 
revenues = revenues.dropna()
revenues
```

Make a training and validation set


```python
# Chronological split
train_size = int(len(revenues) * 0.8)
train = revenues[:train_size]
test = revenues[train_size:]

X_train = train[['lag_1', 'lag_2', 'year_lag']]
y_train = train['revenue']
X_test = test[['lag_1', 'lag_2', 'year_lag']]
y_test = test['revenue']
```


```python
# AR(1) Model
model_ar1 = LinearRegression()
model_ar1.fit(X_train[['lag_1']], y_train)
y_pred_ar1 = model_ar1.predict(X_test[['lag_1']])
print("AR(1) RMSE:", root_mean_squared_error(y_test, y_pred_ar1))

print()
# AR(2) Model
model_ar2 = LinearRegression()
model_ar2.fit(X_train[['lag_1','lag_2']], y_train)
y_pred_ar2 = model_ar2.predict(X_test[['lag_1','lag_2']])
print("AR(2) RMSE:", root_mean_squared_error(y_test, y_pred_ar2))

print()
# AR(1) Model
model_year = LinearRegression()
model_year.fit(X_train[['year_lag']], y_train)
y_pred_year = model_year.predict(X_test[['year_lag']])
print("AR(1) year lag RMSE:", root_mean_squared_error(y_test, y_pred_year))
```

not great? our AR(1) predictions are off by 71 Million and AR(2) is even worse with  82 million!



If we lag by a year we are off by 43 million

if we lag by a year and do AR(1) we get better performance, only 43 million! I think that has to do with the lack of data being stationary. There is definitely some seasonality to the data.


maybe try a walk forward validation approach?


```python
y_test.values
```


```python

# Assuming you have y_test (actual values) and y_pred (predicted values)
# Example data
# y_test = [actual values]
# y_pred = [predicted values]

# Create the plot
plt.figure(figsize=(10, 6))

# Plot actual values
plt.plot(y_test.values, label="Actual Values", marker="o", linestyle="-")

# Plot predicted values
plt.plot(y_pred_ar1, label="-2 Q Lag Predicted", marker="x", linestyle="--")
plt.plot(y_pred_ar2, label="-2&3 Q Lag Predicted", marker="x", linestyle="--")
plt.plot(y_pred_year, label="-1 Year Lag Predicted", marker="x", linestyle="--")

# Add labels, title, and legend
plt.xlabel("barf")
plt.ylabel("Values")
plt.title("Actual vs Predicted Values")
plt.legend()

# Show the plot
plt.show()
```

## Rolling window


```python

from sklearn.model_selection import TimeSeriesSplit

tscv = TimeSeriesSplit(n_splits=5)

for train_index, test_index in tscv.split(revenues):
    train, test = revenues.iloc[train_index], revenues.iloc[test_index]
    X_train, y_train = train[['lag_1', 'lag_2']], train['revenue']
    X_test, y_test = test[['lag_1', 'lag_2']], test['revenue']
    
    model = LinearRegression()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print("RMSE:", root_mean_squared_error(y_test, y_pred))

```


```python
# do a walk on the year lag
from sklearn.model_selection import TimeSeriesSplit

tscv = TimeSeriesSplit(n_splits=5)

for train_index, test_index in tscv.split(revenues):
    train, test = revenues.iloc[train_index], revenues.iloc[test_index]
    X_train, y_train = train[['year_lag']], train['revenue']
    X_test, y_test = test[['year_lag']], test['revenue']
    
    model = LinearRegression()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print("Year lag RMSE:", root_mean_squared_error(y_test, y_pred))
```


```python

```
